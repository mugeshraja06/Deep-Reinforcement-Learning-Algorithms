{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement Learning Algorithms -PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2DyaGHw8sGRCPryZBnmN7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIMybz32QQP0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import gym\n",
        "\n",
        "from torch.distributions.categorical import Categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning_curve(x, scores, figure_file):\n",
        "    running_avg = np.zeros(len(scores))\n",
        "    for i in range(len(running_avg)):\n",
        "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
        "    plt.plot(x, running_avg)\n",
        "    plt.title('Running average of previous 100 scores')\n",
        "    plt.savefig(figure_file)"
      ],
      "metadata": {
        "id": "4jvpUpp-sTeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('tmp/ppo/')"
      ],
      "metadata": {
        "id": "6aHVaJJVwP-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proximal Policy Optimisation (PPO)"
      ],
      "metadata": {
        "id": "g093Ly6QRaoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PPOMemory:\n",
        "    def __init__(self, batch_size):\n",
        "        self.states = []\n",
        "        self.probs = []\n",
        "        self.vals = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.dones = []\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def generate_batches(self):\n",
        "        n_states = len(self.states)\n",
        "        batch_start = np.arange(0, n_states, self.batch_size)\n",
        "        indices = np.arange(n_states, dtype=np.int64)\n",
        "        np.random.shuffle(indices)\n",
        "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
        "\n",
        "        return np.array(self.states),\\\n",
        "                np.array(self.actions),\\\n",
        "                np.array(self.probs),\\\n",
        "                np.array(self.vals),\\\n",
        "                np.array(self.rewards),\\\n",
        "                np.array(self.dones),\\\n",
        "                batches\n",
        "\n",
        "    def store_memory(self, state, action, probs, vals, reward, done):\n",
        "        self.states.append(state)\n",
        "        self.actions.append(action)\n",
        "        self.probs.append(probs)\n",
        "        self.vals.append(vals)\n",
        "        self.rewards.append(reward)\n",
        "        self.dones.append(done)\n",
        "\n",
        "    def clear_memory(self):\n",
        "        self.states = []\n",
        "        self.probs = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.dones = []\n",
        "        self.vals = []\n",
        "\n",
        "class ActorNetwork(nn.Module):\n",
        "    def __init__(self, n_actions, input_dims, alpha,\n",
        "            fc1_dims=256, fc2_dims=256, chkpt_dir='tmp/ppo'):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
        "        self.actor = nn.Sequential(\n",
        "                nn.Linear(*input_dims, fc1_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(fc1_dims, fc2_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(fc2_dims, n_actions),\n",
        "                nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, state):\n",
        "        dist = self.actor(state)\n",
        "        dist = Categorical(dist)\n",
        "        \n",
        "        return dist\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        T.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        self.load_state_dict(T.load(self.checkpoint_file))\n",
        "\n",
        "class CriticNetwork(nn.Module):\n",
        "    def __init__(self, input_dims, alpha, fc1_dims=256, fc2_dims=256,\n",
        "            chkpt_dir='tmp/ppo'):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir, 'critic_torch_ppo')\n",
        "        self.critic = nn.Sequential(\n",
        "                nn.Linear(*input_dims, fc1_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(fc1_dims, fc2_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(fc2_dims, 1)\n",
        "        )\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, state):\n",
        "        value = self.critic(state)\n",
        "\n",
        "        return value\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        T.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        self.load_state_dict(T.load(self.checkpoint_file))\n",
        "\n"
      ],
      "metadata": {
        "id": "gvKVuRUIRXLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, n_actions, input_dims, gamma=0.99, alpha=0.0003, gae_lambda=0.95,\n",
        "            policy_clip=0.2, batch_size=64, n_epochs=10):\n",
        "        self.gamma = gamma\n",
        "        self.policy_clip = policy_clip\n",
        "        self.n_epochs = n_epochs\n",
        "        self.gae_lambda = gae_lambda\n",
        "\n",
        "        self.actor = ActorNetwork(n_actions, input_dims, alpha)\n",
        "        self.critic = CriticNetwork(input_dims, alpha)\n",
        "        self.memory = PPOMemory(batch_size)\n",
        "       \n",
        "    def remember(self, state, action, probs, vals, reward, done):\n",
        "        self.memory.store_memory(state, action, probs, vals, reward, done)\n",
        "\n",
        "    def save_models(self):\n",
        "        print('... saving models ...')\n",
        "        self.actor.save_checkpoint()\n",
        "        self.critic.save_checkpoint()\n",
        "\n",
        "    def load_models(self):\n",
        "        print('... loading models ...')\n",
        "        self.actor.load_checkpoint()\n",
        "        self.critic.load_checkpoint()\n",
        "\n",
        "    def choose_action(self, observation):\n",
        "        state = T.tensor([observation], dtype=T.float).to(self.actor.device)\n",
        "\n",
        "        dist = self.actor(state)\n",
        "        value = self.critic(state)\n",
        "        action = dist.sample()\n",
        "\n",
        "        probs = T.squeeze(dist.log_prob(action)).item()\n",
        "        action = T.squeeze(action).item()\n",
        "        value = T.squeeze(value).item()\n",
        "\n",
        "        return action, probs, value\n",
        "\n",
        "    def learn(self):\n",
        "        for _ in range(self.n_epochs):\n",
        "            state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
        "            reward_arr, dones_arr, batches = \\\n",
        "                    self.memory.generate_batches()\n",
        "\n",
        "            values = vals_arr\n",
        "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
        "\n",
        "            for t in range(len(reward_arr)-1):\n",
        "                discount = 1\n",
        "                a_t = 0\n",
        "                for k in range(t, len(reward_arr)-1):\n",
        "                    a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
        "                            (1-int(dones_arr[k])) - values[k])\n",
        "                    discount *= self.gamma*self.gae_lambda\n",
        "                advantage[t] = a_t\n",
        "            advantage = T.tensor(advantage).to(self.actor.device)\n",
        "\n",
        "            values = T.tensor(values).to(self.actor.device)\n",
        "            for batch in batches:\n",
        "                states = T.tensor(state_arr[batch], dtype=T.float).to(self.actor.device)\n",
        "                old_probs = T.tensor(old_prob_arr[batch]).to(self.actor.device)\n",
        "                actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
        "\n",
        "                dist = self.actor(states)\n",
        "                critic_value = self.critic(states)\n",
        "\n",
        "                critic_value = T.squeeze(critic_value)\n",
        "\n",
        "                new_probs = dist.log_prob(actions)\n",
        "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
        "                #prob_ratio = (new_probs - old_probs).exp()\n",
        "                weighted_probs = advantage[batch] * prob_ratio\n",
        "                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip,\n",
        "                        1+self.policy_clip)*advantage[batch]\n",
        "                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
        "\n",
        "                returns = advantage[batch] + values[batch]\n",
        "                critic_loss = (returns-critic_value)**2\n",
        "                critic_loss = critic_loss.mean()\n",
        "\n",
        "                total_loss = actor_loss + 0.5*critic_loss\n",
        "                self.actor.optimizer.zero_grad()\n",
        "                self.critic.optimizer.zero_grad()\n",
        "                total_loss.backward()\n",
        "                self.actor.optimizer.step()\n",
        "                self.critic.optimizer.step()\n",
        "\n",
        "        self.memory.clear_memory()               "
      ],
      "metadata": {
        "id": "757qTXWxAje7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    env = gym.make('CartPole-v0')\n",
        "    N = 20\n",
        "    batch_size = 5\n",
        "    n_epochs = 4\n",
        "    alpha = 0.0003\n",
        "    agent = Agent(n_actions=env.action_space.n, batch_size=batch_size, \n",
        "                    alpha=alpha, n_epochs=n_epochs, \n",
        "                    input_dims=env.observation_space.shape)\n",
        "    n_games = 300\n",
        "\n",
        "    figure_file = 'tmp/ppo/cartpole.png'\n",
        "\n",
        "    best_score = env.reward_range[0]\n",
        "    score_history = []\n",
        "\n",
        "    learn_iters = 0\n",
        "    avg_score = 0\n",
        "    n_steps = 0\n",
        "\n",
        "    for i in range(n_games):\n",
        "        observation = env.reset()\n",
        "        done = False\n",
        "        score = 0\n",
        "        while not done:\n",
        "            action, prob, val = agent.choose_action(observation)\n",
        "            observation_, reward, done, info = env.step(action)\n",
        "            n_steps += 1\n",
        "            score += reward\n",
        "            agent.remember(observation, action, prob, val, reward, done)\n",
        "            if n_steps % N == 0:\n",
        "                agent.learn()\n",
        "                learn_iters += 1\n",
        "            observation = observation_\n",
        "        score_history.append(score)\n",
        "        avg_score = np.mean(score_history[-100:])\n",
        "\n",
        "        if avg_score > best_score:\n",
        "            best_score = avg_score\n",
        "            agent.save_models()\n",
        "\n",
        "        print('episode', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
        "                'time_steps', n_steps, 'learning_steps', learn_iters)\n",
        "    x = [i+1 for i in range(len(score_history))]\n",
        "    plot_learning_curve(x, score_history, figure_file)"
      ],
      "metadata": {
        "id": "KcB1mX4YRXOw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d24027a4-8a32-41ab-8886-cd44c4ab1e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... saving models ...\n",
            "episode 0 score 9.0 avg score 9.0 time_steps 9 learning_steps 0\n",
            "... saving models ...\n",
            "episode 1 score 25.0 avg score 17.0 time_steps 34 learning_steps 1\n",
            "episode 2 score 12.0 avg score 15.3 time_steps 46 learning_steps 2\n",
            "... saving models ...\n",
            "episode 3 score 32.0 avg score 19.5 time_steps 78 learning_steps 3\n",
            "episode 4 score 16.0 avg score 18.8 time_steps 94 learning_steps 4\n",
            "episode 5 score 12.0 avg score 17.7 time_steps 106 learning_steps 5\n",
            "... saving models ...\n",
            "episode 6 score 42.0 avg score 21.1 time_steps 148 learning_steps 7\n",
            "... saving models ...\n",
            "episode 7 score 37.0 avg score 23.1 time_steps 185 learning_steps 9\n",
            "... saving models ...\n",
            "episode 8 score 41.0 avg score 25.1 time_steps 226 learning_steps 11\n",
            "... saving models ...\n",
            "episode 9 score 47.0 avg score 27.3 time_steps 273 learning_steps 13\n",
            "episode 10 score 27.0 avg score 27.3 time_steps 300 learning_steps 15\n",
            "... saving models ...\n",
            "episode 11 score 29.0 avg score 27.4 time_steps 329 learning_steps 16\n",
            "episode 12 score 18.0 avg score 26.7 time_steps 347 learning_steps 17\n",
            "... saving models ...\n",
            "episode 13 score 69.0 avg score 29.7 time_steps 416 learning_steps 20\n",
            "episode 14 score 16.0 avg score 28.8 time_steps 432 learning_steps 21\n",
            "episode 15 score 15.0 avg score 27.9 time_steps 447 learning_steps 22\n",
            "episode 16 score 21.0 avg score 27.5 time_steps 468 learning_steps 23\n",
            "episode 17 score 38.0 avg score 28.1 time_steps 506 learning_steps 25\n",
            "episode 18 score 15.0 avg score 27.4 time_steps 521 learning_steps 26\n",
            "episode 19 score 13.0 avg score 26.7 time_steps 534 learning_steps 26\n",
            "episode 20 score 14.0 avg score 26.1 time_steps 548 learning_steps 27\n",
            "episode 21 score 11.0 avg score 25.4 time_steps 559 learning_steps 27\n",
            "episode 22 score 19.0 avg score 25.1 time_steps 578 learning_steps 28\n",
            "episode 23 score 18.0 avg score 24.8 time_steps 596 learning_steps 29\n",
            "episode 24 score 19.0 avg score 24.6 time_steps 615 learning_steps 30\n",
            "episode 25 score 15.0 avg score 24.2 time_steps 630 learning_steps 31\n",
            "episode 26 score 32.0 avg score 24.5 time_steps 662 learning_steps 33\n",
            "episode 27 score 23.0 avg score 24.5 time_steps 685 learning_steps 34\n",
            "episode 28 score 39.0 avg score 25.0 time_steps 724 learning_steps 36\n",
            "episode 29 score 72.0 avg score 26.5 time_steps 796 learning_steps 39\n",
            "episode 30 score 58.0 avg score 27.5 time_steps 854 learning_steps 42\n",
            "episode 31 score 32.0 avg score 27.7 time_steps 886 learning_steps 44\n",
            "episode 32 score 33.0 avg score 27.8 time_steps 919 learning_steps 45\n",
            "episode 33 score 31.0 avg score 27.9 time_steps 950 learning_steps 47\n",
            "episode 34 score 21.0 avg score 27.7 time_steps 971 learning_steps 48\n",
            "episode 35 score 39.0 avg score 28.1 time_steps 1010 learning_steps 50\n",
            "episode 36 score 16.0 avg score 27.7 time_steps 1026 learning_steps 51\n",
            "episode 37 score 52.0 avg score 28.4 time_steps 1078 learning_steps 53\n",
            "episode 38 score 25.0 avg score 28.3 time_steps 1103 learning_steps 55\n",
            "episode 39 score 28.0 avg score 28.3 time_steps 1131 learning_steps 56\n",
            "... saving models ...\n",
            "episode 40 score 95.0 avg score 29.9 time_steps 1226 learning_steps 61\n",
            "... saving models ...\n",
            "episode 41 score 46.0 avg score 30.3 time_steps 1272 learning_steps 63\n",
            "episode 42 score 22.0 avg score 30.1 time_steps 1294 learning_steps 64\n",
            "... saving models ...\n",
            "episode 43 score 66.0 avg score 30.9 time_steps 1360 learning_steps 68\n",
            "... saving models ...\n",
            "episode 44 score 43.0 avg score 31.2 time_steps 1403 learning_steps 70\n",
            "... saving models ...\n",
            "episode 45 score 54.0 avg score 31.7 time_steps 1457 learning_steps 72\n",
            "... saving models ...\n",
            "episode 46 score 44.0 avg score 31.9 time_steps 1501 learning_steps 75\n",
            "... saving models ...\n",
            "episode 47 score 52.0 avg score 32.4 time_steps 1553 learning_steps 77\n",
            "... saving models ...\n",
            "episode 48 score 51.0 avg score 32.7 time_steps 1604 learning_steps 80\n",
            "... saving models ...\n",
            "episode 49 score 77.0 avg score 33.6 time_steps 1681 learning_steps 84\n",
            "... saving models ...\n",
            "episode 50 score 46.0 avg score 33.9 time_steps 1727 learning_steps 86\n",
            "... saving models ...\n",
            "episode 51 score 103.0 avg score 35.2 time_steps 1830 learning_steps 91\n",
            "... saving models ...\n",
            "episode 52 score 200.0 avg score 38.3 time_steps 2030 learning_steps 101\n",
            "... saving models ...\n",
            "episode 53 score 127.0 avg score 39.9 time_steps 2157 learning_steps 107\n",
            "... saving models ...\n",
            "episode 54 score 86.0 avg score 40.8 time_steps 2243 learning_steps 112\n",
            "episode 55 score 23.0 avg score 40.5 time_steps 2266 learning_steps 113\n",
            "... saving models ...\n",
            "episode 56 score 91.0 avg score 41.4 time_steps 2357 learning_steps 117\n",
            "episode 57 score 21.0 avg score 41.0 time_steps 2378 learning_steps 118\n",
            "... saving models ...\n",
            "episode 58 score 119.0 avg score 42.3 time_steps 2497 learning_steps 124\n",
            "... saving models ...\n",
            "episode 59 score 68.0 avg score 42.8 time_steps 2565 learning_steps 128\n",
            "episode 60 score 36.0 avg score 42.6 time_steps 2601 learning_steps 130\n",
            "episode 61 score 36.0 avg score 42.5 time_steps 2637 learning_steps 131\n",
            "... saving models ...\n",
            "episode 62 score 106.0 avg score 43.5 time_steps 2743 learning_steps 137\n",
            "... saving models ...\n",
            "episode 63 score 100.0 avg score 44.4 time_steps 2843 learning_steps 142\n",
            "... saving models ...\n",
            "episode 64 score 121.0 avg score 45.6 time_steps 2964 learning_steps 148\n",
            "... saving models ...\n",
            "episode 65 score 159.0 avg score 47.3 time_steps 3123 learning_steps 156\n",
            "... saving models ...\n",
            "episode 66 score 112.0 avg score 48.3 time_steps 3235 learning_steps 161\n",
            "... saving models ...\n",
            "episode 67 score 177.0 avg score 50.2 time_steps 3412 learning_steps 170\n",
            "... saving models ...\n",
            "episode 68 score 116.0 avg score 51.1 time_steps 3528 learning_steps 176\n",
            "episode 69 score 33.0 avg score 50.9 time_steps 3561 learning_steps 178\n",
            "episode 70 score 51.0 avg score 50.9 time_steps 3612 learning_steps 180\n",
            "... saving models ...\n",
            "episode 71 score 87.0 avg score 51.4 time_steps 3699 learning_steps 184\n",
            "... saving models ...\n",
            "episode 72 score 200.0 avg score 53.4 time_steps 3899 learning_steps 194\n",
            "... saving models ...\n",
            "episode 73 score 141.0 avg score 54.6 time_steps 4040 learning_steps 202\n",
            "... saving models ...\n",
            "episode 74 score 120.0 avg score 55.5 time_steps 4160 learning_steps 208\n",
            "... saving models ...\n",
            "episode 75 score 200.0 avg score 57.4 time_steps 4360 learning_steps 218\n",
            "... saving models ...\n",
            "episode 76 score 108.0 avg score 58.0 time_steps 4468 learning_steps 223\n",
            "... saving models ...\n",
            "episode 77 score 200.0 avg score 59.8 time_steps 4668 learning_steps 233\n",
            "... saving models ...\n",
            "episode 78 score 173.0 avg score 61.3 time_steps 4841 learning_steps 242\n",
            "... saving models ...\n",
            "episode 79 score 106.0 avg score 61.8 time_steps 4947 learning_steps 247\n",
            "... saving models ...\n",
            "episode 80 score 156.0 avg score 63.0 time_steps 5103 learning_steps 255\n",
            "... saving models ...\n",
            "episode 81 score 141.0 avg score 64.0 time_steps 5244 learning_steps 262\n",
            "... saving models ...\n",
            "episode 82 score 163.0 avg score 65.1 time_steps 5407 learning_steps 270\n",
            "... saving models ...\n",
            "episode 83 score 144.0 avg score 66.1 time_steps 5551 learning_steps 277\n",
            "... saving models ...\n",
            "episode 84 score 200.0 avg score 67.7 time_steps 5751 learning_steps 287\n",
            "... saving models ...\n",
            "episode 85 score 200.0 avg score 69.2 time_steps 5951 learning_steps 297\n",
            "... saving models ...\n",
            "episode 86 score 152.0 avg score 70.1 time_steps 6103 learning_steps 305\n",
            "... saving models ...\n",
            "episode 87 score 200.0 avg score 71.6 time_steps 6303 learning_steps 315\n",
            "... saving models ...\n",
            "episode 88 score 200.0 avg score 73.1 time_steps 6503 learning_steps 325\n",
            "... saving models ...\n",
            "episode 89 score 200.0 avg score 74.5 time_steps 6703 learning_steps 335\n",
            "... saving models ...\n",
            "episode 90 score 200.0 avg score 75.9 time_steps 6903 learning_steps 345\n",
            "... saving models ...\n",
            "episode 91 score 121.0 avg score 76.3 time_steps 7024 learning_steps 351\n",
            "... saving models ...\n",
            "episode 92 score 190.0 avg score 77.6 time_steps 7214 learning_steps 360\n",
            "... saving models ...\n",
            "episode 93 score 200.0 avg score 78.9 time_steps 7414 learning_steps 370\n",
            "... saving models ...\n",
            "episode 94 score 170.0 avg score 79.8 time_steps 7584 learning_steps 379\n",
            "... saving models ...\n",
            "episode 95 score 200.0 avg score 81.1 time_steps 7784 learning_steps 389\n",
            "... saving models ...\n",
            "episode 96 score 200.0 avg score 82.3 time_steps 7984 learning_steps 399\n",
            "... saving models ...\n",
            "episode 97 score 200.0 avg score 83.5 time_steps 8184 learning_steps 409\n",
            "... saving models ...\n",
            "episode 98 score 116.0 avg score 83.8 time_steps 8300 learning_steps 415\n",
            "... saving models ...\n",
            "episode 99 score 107.0 avg score 84.1 time_steps 8407 learning_steps 420\n",
            "... saving models ...\n",
            "episode 100 score 112.0 avg score 85.1 time_steps 8519 learning_steps 425\n",
            "... saving models ...\n",
            "episode 101 score 133.0 avg score 86.2 time_steps 8652 learning_steps 432\n",
            "... saving models ...\n",
            "episode 102 score 154.0 avg score 87.6 time_steps 8806 learning_steps 440\n",
            "... saving models ...\n",
            "episode 103 score 200.0 avg score 89.3 time_steps 9006 learning_steps 450\n",
            "... saving models ...\n",
            "episode 104 score 144.0 avg score 90.6 time_steps 9150 learning_steps 457\n",
            "... saving models ...\n",
            "episode 105 score 173.0 avg score 92.2 time_steps 9323 learning_steps 466\n",
            "... saving models ...\n",
            "episode 106 score 183.0 avg score 93.6 time_steps 9506 learning_steps 475\n",
            "... saving models ...\n",
            "episode 107 score 200.0 avg score 95.2 time_steps 9706 learning_steps 485\n",
            "... saving models ...\n",
            "episode 108 score 200.0 avg score 96.8 time_steps 9906 learning_steps 495\n",
            "... saving models ...\n",
            "episode 109 score 200.0 avg score 98.3 time_steps 10106 learning_steps 505\n",
            "... saving models ...\n",
            "episode 110 score 171.0 avg score 99.8 time_steps 10277 learning_steps 513\n",
            "... saving models ...\n",
            "episode 111 score 192.0 avg score 101.4 time_steps 10469 learning_steps 523\n",
            "... saving models ...\n",
            "episode 112 score 200.0 avg score 103.2 time_steps 10669 learning_steps 533\n",
            "... saving models ...\n",
            "episode 113 score 200.0 avg score 104.5 time_steps 10869 learning_steps 543\n",
            "... saving models ...\n",
            "episode 114 score 200.0 avg score 106.4 time_steps 11069 learning_steps 553\n",
            "... saving models ...\n",
            "episode 115 score 200.0 avg score 108.2 time_steps 11269 learning_steps 563\n",
            "... saving models ...\n",
            "episode 116 score 200.0 avg score 110.0 time_steps 11469 learning_steps 573\n",
            "... saving models ...\n",
            "episode 117 score 200.0 avg score 111.6 time_steps 11669 learning_steps 583\n",
            "... saving models ...\n",
            "episode 118 score 200.0 avg score 113.5 time_steps 11869 learning_steps 593\n",
            "... saving models ...\n",
            "episode 119 score 170.0 avg score 115.0 time_steps 12039 learning_steps 601\n",
            "... saving models ...\n",
            "episode 120 score 133.0 avg score 116.2 time_steps 12172 learning_steps 608\n",
            "... saving models ...\n",
            "episode 121 score 200.0 avg score 118.1 time_steps 12372 learning_steps 618\n",
            "... saving models ...\n",
            "episode 122 score 200.0 avg score 119.9 time_steps 12572 learning_steps 628\n",
            "... saving models ...\n",
            "episode 123 score 200.0 avg score 121.8 time_steps 12772 learning_steps 638\n",
            "... saving models ...\n",
            "episode 124 score 200.0 avg score 123.6 time_steps 12972 learning_steps 648\n",
            "... saving models ...\n",
            "episode 125 score 200.0 avg score 125.4 time_steps 13172 learning_steps 658\n",
            "... saving models ...\n",
            "episode 126 score 200.0 avg score 127.1 time_steps 13372 learning_steps 668\n",
            "... saving models ...\n",
            "episode 127 score 200.0 avg score 128.9 time_steps 13572 learning_steps 678\n",
            "... saving models ...\n",
            "episode 128 score 200.0 avg score 130.5 time_steps 13772 learning_steps 688\n",
            "... saving models ...\n",
            "episode 129 score 200.0 avg score 131.8 time_steps 13972 learning_steps 698\n",
            "... saving models ...\n",
            "episode 130 score 200.0 avg score 133.2 time_steps 14172 learning_steps 708\n",
            "... saving models ...\n",
            "episode 131 score 200.0 avg score 134.9 time_steps 14372 learning_steps 718\n",
            "... saving models ...\n",
            "episode 132 score 200.0 avg score 136.5 time_steps 14572 learning_steps 728\n",
            "... saving models ...\n",
            "episode 133 score 200.0 avg score 138.2 time_steps 14772 learning_steps 738\n",
            "... saving models ...\n",
            "episode 134 score 200.0 avg score 140.0 time_steps 14972 learning_steps 748\n",
            "... saving models ...\n",
            "episode 135 score 200.0 avg score 141.6 time_steps 15172 learning_steps 758\n",
            "... saving models ...\n",
            "episode 136 score 200.0 avg score 143.5 time_steps 15372 learning_steps 768\n",
            "... saving models ...\n",
            "episode 137 score 200.0 avg score 144.9 time_steps 15572 learning_steps 778\n",
            "... saving models ...\n",
            "episode 138 score 200.0 avg score 146.7 time_steps 15772 learning_steps 788\n",
            "... saving models ...\n",
            "episode 139 score 200.0 avg score 148.4 time_steps 15972 learning_steps 798\n",
            "episode 140 score 76.0 avg score 148.2 time_steps 16048 learning_steps 802\n",
            "... saving models ...\n",
            "episode 141 score 190.0 avg score 149.7 time_steps 16238 learning_steps 811\n",
            "... saving models ...\n",
            "episode 142 score 24.0 avg score 149.7 time_steps 16262 learning_steps 813\n",
            "episode 143 score 14.0 avg score 149.2 time_steps 16276 learning_steps 813\n",
            "... saving models ...\n",
            "episode 144 score 169.0 avg score 150.4 time_steps 16445 learning_steps 822\n",
            "... saving models ...\n",
            "episode 145 score 200.0 avg score 151.9 time_steps 16645 learning_steps 832\n",
            "... saving models ...\n",
            "episode 146 score 200.0 avg score 153.4 time_steps 16845 learning_steps 842\n",
            "... saving models ...\n",
            "episode 147 score 200.0 avg score 154.9 time_steps 17045 learning_steps 852\n",
            "... saving models ...\n",
            "episode 148 score 200.0 avg score 156.4 time_steps 17245 learning_steps 862\n",
            "... saving models ...\n",
            "episode 149 score 172.0 avg score 157.4 time_steps 17417 learning_steps 870\n",
            "... saving models ...\n",
            "episode 150 score 190.0 avg score 158.8 time_steps 17607 learning_steps 880\n",
            "... saving models ...\n",
            "episode 151 score 167.0 avg score 159.4 time_steps 17774 learning_steps 888\n",
            "episode 152 score 165.0 avg score 159.1 time_steps 17939 learning_steps 896\n",
            "... saving models ...\n",
            "episode 153 score 168.0 avg score 159.5 time_steps 18107 learning_steps 905\n",
            "... saving models ...\n",
            "episode 154 score 130.0 avg score 159.9 time_steps 18237 learning_steps 911\n",
            "... saving models ...\n",
            "episode 155 score 155.0 avg score 161.3 time_steps 18392 learning_steps 919\n",
            "... saving models ...\n",
            "episode 156 score 163.0 avg score 162.0 time_steps 18555 learning_steps 927\n",
            "... saving models ...\n",
            "episode 157 score 148.0 avg score 163.2 time_steps 18703 learning_steps 935\n",
            "... saving models ...\n",
            "episode 158 score 179.0 avg score 163.8 time_steps 18882 learning_steps 944\n",
            "... saving models ...\n",
            "episode 159 score 173.0 avg score 164.9 time_steps 19055 learning_steps 952\n",
            "... saving models ...\n",
            "episode 160 score 178.0 avg score 166.3 time_steps 19233 learning_steps 961\n",
            "... saving models ...\n",
            "episode 161 score 200.0 avg score 168.0 time_steps 19433 learning_steps 971\n",
            "... saving models ...\n",
            "episode 162 score 150.0 avg score 168.4 time_steps 19583 learning_steps 979\n",
            "... saving models ...\n",
            "episode 163 score 180.0 avg score 169.2 time_steps 19763 learning_steps 988\n",
            "... saving models ...\n",
            "episode 164 score 200.0 avg score 170.0 time_steps 19963 learning_steps 998\n",
            "... saving models ...\n",
            "episode 165 score 200.0 avg score 170.4 time_steps 20163 learning_steps 1008\n",
            "... saving models ...\n",
            "episode 166 score 200.0 avg score 171.3 time_steps 20363 learning_steps 1018\n",
            "... saving models ...\n",
            "episode 167 score 200.0 avg score 171.5 time_steps 20563 learning_steps 1028\n",
            "... saving models ...\n",
            "episode 168 score 200.0 avg score 172.3 time_steps 20763 learning_steps 1038\n",
            "... saving models ...\n",
            "episode 169 score 200.0 avg score 174.0 time_steps 20963 learning_steps 1048\n",
            "... saving models ...\n",
            "episode 170 score 200.0 avg score 175.5 time_steps 21163 learning_steps 1058\n",
            "... saving models ...\n",
            "episode 171 score 200.0 avg score 176.6 time_steps 21363 learning_steps 1068\n",
            "episode 172 score 200.0 avg score 176.6 time_steps 21563 learning_steps 1078\n",
            "... saving models ...\n",
            "episode 173 score 200.0 avg score 177.2 time_steps 21763 learning_steps 1088\n",
            "... saving models ...\n",
            "episode 174 score 200.0 avg score 178.0 time_steps 21963 learning_steps 1098\n",
            "episode 175 score 200.0 avg score 178.0 time_steps 22163 learning_steps 1108\n",
            "... saving models ...\n",
            "episode 176 score 200.0 avg score 178.9 time_steps 22363 learning_steps 1118\n",
            "episode 177 score 200.0 avg score 178.9 time_steps 22563 learning_steps 1128\n",
            "... saving models ...\n",
            "episode 178 score 200.0 avg score 179.2 time_steps 22763 learning_steps 1138\n",
            "... saving models ...\n",
            "episode 179 score 200.0 avg score 180.2 time_steps 22963 learning_steps 1148\n",
            "... saving models ...\n",
            "episode 180 score 200.0 avg score 180.6 time_steps 23163 learning_steps 1158\n",
            "... saving models ...\n",
            "episode 181 score 200.0 avg score 181.2 time_steps 23363 learning_steps 1168\n",
            "... saving models ...\n",
            "episode 182 score 200.0 avg score 181.6 time_steps 23563 learning_steps 1178\n",
            "... saving models ...\n",
            "episode 183 score 200.0 avg score 182.1 time_steps 23763 learning_steps 1188\n",
            "episode 184 score 200.0 avg score 182.1 time_steps 23963 learning_steps 1198\n",
            "episode 185 score 200.0 avg score 182.1 time_steps 24163 learning_steps 1208\n",
            "... saving models ...\n",
            "episode 186 score 200.0 avg score 182.6 time_steps 24363 learning_steps 1218\n",
            "episode 187 score 200.0 avg score 182.6 time_steps 24563 learning_steps 1228\n",
            "episode 188 score 200.0 avg score 182.6 time_steps 24763 learning_steps 1238\n",
            "episode 189 score 142.0 avg score 182.0 time_steps 24905 learning_steps 1245\n",
            "episode 190 score 200.0 avg score 182.0 time_steps 25105 learning_steps 1255\n",
            "episode 191 score 46.0 avg score 181.3 time_steps 25151 learning_steps 1257\n",
            "episode 192 score 83.0 avg score 180.2 time_steps 25234 learning_steps 1261\n",
            "episode 193 score 200.0 avg score 180.2 time_steps 25434 learning_steps 1271\n",
            "episode 194 score 71.0 avg score 179.2 time_steps 25505 learning_steps 1275\n",
            "episode 195 score 200.0 avg score 179.2 time_steps 25705 learning_steps 1285\n",
            "episode 196 score 200.0 avg score 179.2 time_steps 25905 learning_steps 1295\n",
            "episode 197 score 200.0 avg score 179.2 time_steps 26105 learning_steps 1305\n",
            "episode 198 score 200.0 avg score 180.1 time_steps 26305 learning_steps 1315\n",
            "episode 199 score 200.0 avg score 181.0 time_steps 26505 learning_steps 1325\n",
            "episode 200 score 200.0 avg score 181.9 time_steps 26705 learning_steps 1335\n",
            "episode 201 score 200.0 avg score 182.5 time_steps 26905 learning_steps 1345\n",
            "... saving models ...\n",
            "episode 202 score 200.0 avg score 183.0 time_steps 27105 learning_steps 1355\n",
            "episode 203 score 200.0 avg score 183.0 time_steps 27305 learning_steps 1365\n",
            "... saving models ...\n",
            "episode 204 score 200.0 avg score 183.6 time_steps 27505 learning_steps 1375\n",
            "... saving models ...\n",
            "episode 205 score 200.0 avg score 183.8 time_steps 27705 learning_steps 1385\n",
            "... saving models ...\n",
            "episode 206 score 200.0 avg score 184.0 time_steps 27905 learning_steps 1395\n",
            "episode 207 score 200.0 avg score 184.0 time_steps 28105 learning_steps 1405\n",
            "episode 208 score 200.0 avg score 184.0 time_steps 28305 learning_steps 1415\n",
            "episode 209 score 200.0 avg score 184.0 time_steps 28505 learning_steps 1425\n",
            "... saving models ...\n",
            "episode 210 score 200.0 avg score 184.3 time_steps 28705 learning_steps 1435\n",
            "episode 211 score 143.0 avg score 183.8 time_steps 28848 learning_steps 1442\n",
            "episode 212 score 200.0 avg score 183.8 time_steps 29048 learning_steps 1452\n",
            "episode 213 score 200.0 avg score 183.8 time_steps 29248 learning_steps 1462\n",
            "episode 214 score 200.0 avg score 183.8 time_steps 29448 learning_steps 1472\n",
            "episode 215 score 200.0 avg score 183.8 time_steps 29648 learning_steps 1482\n",
            "episode 216 score 200.0 avg score 183.8 time_steps 29848 learning_steps 1492\n",
            "episode 217 score 200.0 avg score 183.8 time_steps 30048 learning_steps 1502\n",
            "episode 218 score 200.0 avg score 183.8 time_steps 30248 learning_steps 1512\n",
            "episode 219 score 200.0 avg score 184.1 time_steps 30448 learning_steps 1522\n",
            "... saving models ...\n",
            "episode 220 score 200.0 avg score 184.8 time_steps 30648 learning_steps 1532\n",
            "episode 221 score 132.0 avg score 184.1 time_steps 30780 learning_steps 1539\n",
            "episode 222 score 200.0 avg score 184.1 time_steps 30980 learning_steps 1549\n",
            "episode 223 score 147.0 avg score 183.6 time_steps 31127 learning_steps 1556\n",
            "episode 224 score 200.0 avg score 183.6 time_steps 31327 learning_steps 1566\n",
            "episode 225 score 200.0 avg score 183.6 time_steps 31527 learning_steps 1576\n",
            "episode 226 score 200.0 avg score 183.6 time_steps 31727 learning_steps 1586\n",
            "episode 227 score 200.0 avg score 183.6 time_steps 31927 learning_steps 1596\n",
            "episode 228 score 200.0 avg score 183.6 time_steps 32127 learning_steps 1606\n",
            "episode 229 score 200.0 avg score 183.6 time_steps 32327 learning_steps 1616\n",
            "episode 230 score 200.0 avg score 183.6 time_steps 32527 learning_steps 1626\n",
            "episode 231 score 200.0 avg score 183.6 time_steps 32727 learning_steps 1636\n",
            "episode 232 score 200.0 avg score 183.6 time_steps 32927 learning_steps 1646\n",
            "episode 233 score 200.0 avg score 183.6 time_steps 33127 learning_steps 1656\n",
            "episode 234 score 200.0 avg score 183.6 time_steps 33327 learning_steps 1666\n",
            "episode 235 score 200.0 avg score 183.6 time_steps 33527 learning_steps 1676\n",
            "episode 236 score 200.0 avg score 183.6 time_steps 33727 learning_steps 1686\n",
            "episode 237 score 67.0 avg score 182.2 time_steps 33794 learning_steps 1689\n",
            "episode 238 score 200.0 avg score 182.2 time_steps 33994 learning_steps 1699\n",
            "episode 239 score 200.0 avg score 182.2 time_steps 34194 learning_steps 1709\n",
            "episode 240 score 200.0 avg score 183.5 time_steps 34394 learning_steps 1719\n",
            "episode 241 score 200.0 avg score 183.6 time_steps 34594 learning_steps 1729\n",
            "... saving models ...\n",
            "episode 242 score 200.0 avg score 185.3 time_steps 34794 learning_steps 1739\n",
            "... saving models ...\n",
            "episode 243 score 200.0 avg score 187.2 time_steps 34994 learning_steps 1749\n",
            "... saving models ...\n",
            "episode 244 score 200.0 avg score 187.5 time_steps 35194 learning_steps 1759\n",
            "episode 245 score 200.0 avg score 187.5 time_steps 35394 learning_steps 1769\n",
            "episode 246 score 200.0 avg score 187.5 time_steps 35594 learning_steps 1779\n",
            "episode 247 score 200.0 avg score 187.5 time_steps 35794 learning_steps 1789\n",
            "episode 248 score 200.0 avg score 187.5 time_steps 35994 learning_steps 1799\n",
            "... saving models ...\n",
            "episode 249 score 200.0 avg score 187.8 time_steps 36194 learning_steps 1809\n",
            "... saving models ...\n",
            "episode 250 score 200.0 avg score 187.9 time_steps 36394 learning_steps 1819\n",
            "... saving models ...\n",
            "episode 251 score 200.0 avg score 188.2 time_steps 36594 learning_steps 1829\n",
            "... saving models ...\n",
            "episode 252 score 200.0 avg score 188.6 time_steps 36794 learning_steps 1839\n",
            "... saving models ...\n",
            "episode 253 score 200.0 avg score 188.9 time_steps 36994 learning_steps 1849\n",
            "... saving models ...\n",
            "episode 254 score 200.0 avg score 189.6 time_steps 37194 learning_steps 1859\n",
            "... saving models ...\n",
            "episode 255 score 200.0 avg score 190.0 time_steps 37394 learning_steps 1869\n",
            "... saving models ...\n",
            "episode 256 score 200.0 avg score 190.4 time_steps 37594 learning_steps 1879\n",
            "... saving models ...\n",
            "episode 257 score 200.0 avg score 190.9 time_steps 37794 learning_steps 1889\n",
            "... saving models ...\n",
            "episode 258 score 200.0 avg score 191.1 time_steps 37994 learning_steps 1899\n",
            "... saving models ...\n",
            "episode 259 score 199.0 avg score 191.4 time_steps 38193 learning_steps 1909\n",
            "... saving models ...\n",
            "episode 260 score 200.0 avg score 191.6 time_steps 38393 learning_steps 1919\n",
            "episode 261 score 200.0 avg score 191.6 time_steps 38593 learning_steps 1929\n",
            "... saving models ...\n",
            "episode 262 score 200.0 avg score 192.1 time_steps 38793 learning_steps 1939\n",
            "... saving models ...\n",
            "episode 263 score 200.0 avg score 192.3 time_steps 38993 learning_steps 1949\n",
            "episode 264 score 200.0 avg score 192.3 time_steps 39193 learning_steps 1959\n",
            "episode 265 score 200.0 avg score 192.3 time_steps 39393 learning_steps 1969\n",
            "episode 266 score 200.0 avg score 192.3 time_steps 39593 learning_steps 1979\n",
            "episode 267 score 200.0 avg score 192.3 time_steps 39793 learning_steps 1989\n",
            "episode 268 score 200.0 avg score 192.3 time_steps 39993 learning_steps 1999\n",
            "episode 269 score 200.0 avg score 192.3 time_steps 40193 learning_steps 2009\n",
            "episode 270 score 200.0 avg score 192.3 time_steps 40393 learning_steps 2019\n",
            "episode 271 score 200.0 avg score 192.3 time_steps 40593 learning_steps 2029\n",
            "episode 272 score 200.0 avg score 192.3 time_steps 40793 learning_steps 2039\n",
            "episode 273 score 200.0 avg score 192.3 time_steps 40993 learning_steps 2049\n",
            "episode 274 score 200.0 avg score 192.3 time_steps 41193 learning_steps 2059\n",
            "episode 275 score 200.0 avg score 192.3 time_steps 41393 learning_steps 2069\n",
            "episode 276 score 200.0 avg score 192.3 time_steps 41593 learning_steps 2079\n",
            "episode 277 score 200.0 avg score 192.3 time_steps 41793 learning_steps 2089\n",
            "episode 278 score 200.0 avg score 192.3 time_steps 41993 learning_steps 2099\n",
            "episode 279 score 200.0 avg score 192.3 time_steps 42193 learning_steps 2109\n",
            "episode 280 score 200.0 avg score 192.3 time_steps 42393 learning_steps 2119\n",
            "episode 281 score 200.0 avg score 192.3 time_steps 42593 learning_steps 2129\n",
            "episode 282 score 200.0 avg score 192.3 time_steps 42793 learning_steps 2139\n",
            "episode 283 score 183.0 avg score 192.1 time_steps 42976 learning_steps 2148\n",
            "episode 284 score 172.0 avg score 191.8 time_steps 43148 learning_steps 2157\n",
            "episode 285 score 200.0 avg score 191.8 time_steps 43348 learning_steps 2167\n",
            "episode 286 score 200.0 avg score 191.8 time_steps 43548 learning_steps 2177\n",
            "episode 287 score 200.0 avg score 191.8 time_steps 43748 learning_steps 2187\n",
            "episode 288 score 200.0 avg score 191.8 time_steps 43948 learning_steps 2197\n",
            "... saving models ...\n",
            "episode 289 score 200.0 avg score 192.4 time_steps 44148 learning_steps 2207\n",
            "episode 290 score 200.0 avg score 192.4 time_steps 44348 learning_steps 2217\n",
            "... saving models ...\n",
            "episode 291 score 200.0 avg score 194.0 time_steps 44548 learning_steps 2227\n",
            "... saving models ...\n",
            "episode 292 score 200.0 avg score 195.1 time_steps 44748 learning_steps 2237\n",
            "episode 293 score 200.0 avg score 195.1 time_steps 44948 learning_steps 2247\n",
            "... saving models ...\n",
            "episode 294 score 200.0 avg score 196.4 time_steps 45148 learning_steps 2257\n",
            "episode 295 score 200.0 avg score 196.4 time_steps 45348 learning_steps 2267\n",
            "episode 296 score 200.0 avg score 196.4 time_steps 45548 learning_steps 2277\n",
            "episode 297 score 200.0 avg score 196.4 time_steps 45748 learning_steps 2287\n",
            "episode 298 score 200.0 avg score 196.4 time_steps 45948 learning_steps 2297\n",
            "episode 299 score 200.0 avg score 196.4 time_steps 46148 learning_steps 2307\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8negE8NbRXQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0ttK68UqRXVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kQ2ffmRGRXW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CY9NPJsVRXbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xioxtR17RXc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AGT4HutVRXhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O7IC6rpbRXjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s27TSSg4RXnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vXD9dzFwRXo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gVEgJXYoRXtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TKo_SxZDRXu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tnjYv1gzRXzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i9ntcXVLRX1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Gc3PH82RX5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DZFqI6iPRYxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "boVvHCB8RYza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rN8XcqWcRY4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jF-4iE-xRY50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8dhMFjPKRY9I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}